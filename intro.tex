%!TEX root = p.tex
\section{Introduction}
Newspapers chronicle current events in great detail and so by utilizing newspaper archives we can gain a window into the past. However these newspaper archives are often massive in size and are filled with detailed text information. Because this information is typically specific to a topic and so large, effective visualization techniques are needed to help researchers pick out macroscopic trends from these archives.

Among the macroscopic trends we initially thought journalists would be interested in were the lifetime of individual stories, the periodic rise and fall of topics, and the coverage of long term events over time (for example a foreign war). All of these examples would be difficult for someone skimming through these archives to identify and measure. After interviewing several journalists, the type of trends we wanted to identify changed but the problem of identifying these macroscopic trends was reaffirmed.

In this paper, we develop two different visualizations to help gain insight into these newspaper archives. Our approach was first interviewing different journalists about their workflows and interests and then moving on to iterative development of prototypes based on their feedback. We conclude with the two visualizations but also propose future work to help merge them together.

The archive data set we used to develop these visualizations has been provided by Geoff McGhee, a Knight Fellow at Stanford's Bill Lane Center for the American West. The data was provided in the form of a thirteen gigabyte archive of more than a decade of articles from the Los Angles Times, Baltimore Sun, and the Chicago Tribune. In total, the set nearly contained two and a half million XML files, each of which corresponded to an article. Additionally the XML files contained metadata such as author, date, section name, page number, title, abstract, and full text of the article.


